{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      4961\n",
      "           1       0.88      0.90      0.89      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "imdb_data = pd.read_csv('IMDB-Dataset.csv')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply preprocessing to reviews\n",
    "imdb_data['cleaned_review'] = imdb_data['review'].apply(preprocess_text)\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X = imdb_data['cleaned_review']\n",
    "y = imdb_data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Training a Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'movie',\n",
       " 'is',\n",
       " 'awful',\n",
       " ',',\n",
       " 'I',\n",
       " 'ca',\n",
       " \"n't\",\n",
       " 'even',\n",
       " 'be',\n",
       " 'bothered',\n",
       " 'to',\n",
       " 'write',\n",
       " 'a',\n",
       " 'review',\n",
       " 'on',\n",
       " 'this',\n",
       " 'garbage',\n",
       " '!',\n",
       " 'All',\n",
       " 'i',\n",
       " 'will',\n",
       " 'say',\n",
       " 'it',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'boring',\n",
       " 'films',\n",
       " 'I',\n",
       " \"'ve\",\n",
       " 'ever',\n",
       " 'seen.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'And',\n",
       " 'the',\n",
       " 'acting',\n",
       " 'is',\n",
       " 'very',\n",
       " 'bad',\n",
       " '.',\n",
       " 'The',\n",
       " 'boy',\n",
       " 'who',\n",
       " 'plays',\n",
       " 'the',\n",
       " 'main',\n",
       " 'character',\n",
       " 'really',\n",
       " 'annoys',\n",
       " 'me',\n",
       " ',',\n",
       " 'he',\n",
       " \"'s\",\n",
       " 'got',\n",
       " 'the',\n",
       " 'same',\n",
       " 'expression',\n",
       " 'on',\n",
       " 'his',\n",
       " 'face',\n",
       " 'through',\n",
       " 'out',\n",
       " 'the',\n",
       " 'movie',\n",
       " '.',\n",
       " 'I',\n",
       " 'just',\n",
       " 'want',\n",
       " 'to',\n",
       " 'slap',\n",
       " 'him',\n",
       " '!',\n",
       " 'Basically',\n",
       " '80',\n",
       " '%',\n",
       " 'of',\n",
       " 'the',\n",
       " 'movie',\n",
       " 'is',\n",
       " 'slow',\n",
       " 'motion',\n",
       " 'shots',\n",
       " 'of',\n",
       " 'skateboarders',\n",
       " ',',\n",
       " 'weird',\n",
       " 'music',\n",
       " ',',\n",
       " 'and',\n",
       " 'utter']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "\n",
    "im=pd.read_csv('IMDB-Dataset.csv')\n",
    "\n",
    "tokens=nltk.word_tokenize(im['review'][1000])\n",
    "tokens[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('awful', 'JJ'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('ca', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('even', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('bothered', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('write', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('review', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('garbage', 'NN'),\n",
       " ('!', '.'),\n",
       " ('All', 'DT'),\n",
       " ('i', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('say', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('boring', 'JJ'),\n",
       " ('films', 'NNS'),\n",
       " ('I', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('ever', 'RB'),\n",
       " ('seen.', 'VBN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('And', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('acting', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('very', 'RB'),\n",
       " ('bad', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('boy', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('plays', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('main', 'JJ'),\n",
       " ('character', 'NN'),\n",
       " ('really', 'RB'),\n",
       " ('annoys', 'VBZ'),\n",
       " ('me', 'PRP'),\n",
       " (',', ','),\n",
       " ('he', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('got', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('same', 'JJ'),\n",
       " ('expression', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('face', 'NN'),\n",
       " ('through', 'IN'),\n",
       " ('out', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('slap', 'VB'),\n",
       " ('him', 'PRP'),\n",
       " ('!', '.'),\n",
       " ('Basically', 'RB'),\n",
       " ('80', 'CD'),\n",
       " ('%', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('movie', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('slow', 'JJ'),\n",
       " ('motion', 'NN'),\n",
       " ('shots', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('skateboarders', 'NNS'),\n",
       " (',', ','),\n",
       " ('weird', 'JJ'),\n",
       " ('music', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('utter', 'JJ'),\n",
       " ('sh', 'NN'),\n",
       " ('*', 'NNP'),\n",
       " ('t', 'NN'),\n",
       " ('..', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('Apparently', 'NNP'),\n",
       " ('I', 'PRP'),\n",
       " (\"'ve\", 'VBP'),\n",
       " ('got', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('write', 'VB'),\n",
       " ('at', 'IN'),\n",
       " ('least', 'JJS'),\n",
       " ('10', 'CD'),\n",
       " ('lines', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('text', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('submit', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('comment', 'NN'),\n",
       " (',', ','),\n",
       " ('so', 'IN'),\n",
       " ('I', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('use', 'VB'),\n",
       " ('up', 'RP'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('more', 'JJR'),\n",
       " ('lines', 'NNS'),\n",
       " ('by', 'IN'),\n",
       " ('saying', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('lead', 'NN'),\n",
       " ('character', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('got', 'VBD'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('those', 'DT'),\n",
       " ('faces', 'VBZ'),\n",
       " ('you', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('slap', 'VB'),\n",
       " ('!', '.'),\n",
       " ('<', 'JJ'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('Meh', 'NNP'),\n",
       " ('i', 'NN'),\n",
       " ('give', 'VBP'),\n",
       " ('up', 'RP'),\n",
       " ('..', 'RB'),\n",
       " ('THIS', 'NNP'),\n",
       " ('MOVIE', 'NNP'),\n",
       " ('SUCKS', 'NNP'),\n",
       " ('!', '.'),\n",
       " ('!', '.'),\n",
       " ('!', '.'),\n",
       " ('!', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.pos_tag(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
